{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "\n",
    "3. Prepare the whole pipeline\n",
    "    1. Data augmentation\n",
    "        - First take the unaugmented original dataset and proceed\n",
    "        -  Augment the data with a predefined seed for each of the following techniques: rotation, flipping, contrast, brightness change, random erasing\n",
    "    2. Choose hyperparameters\n",
    "        - For the hyper-parameters related to the training process we chose batch size, learning rate, and number of epochs\n",
    "        - For the hyper-parameters related to Regularization we decided to use L2 Regularization (Weight Decay) and Dropout Rate\n",
    "    3. Train each of the prepared models on the augmented dataset for a chosen augmentation technique\n",
    "    4. Test and collect data regarding modelsâ€™ performance on the augmented dataset\n",
    "    5. Repeat several times (>=3) from 3.\n",
    "    6. Choose different values for hyperparameters and start from 3.\n",
    "    7. Choose the next augmentation technique and start from 2.\n",
    "    8. Repeat the process starting from 1. several times (>=3) with a different seed each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization\n",
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move 5400 images from each class from valid to train\n",
    " - There is a safety check, if it has been already done it won't do it again :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = './Dataset/valid'\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    if subdir != rootdir:\n",
    "        for subsubdir, subdirs, files in os.walk(subdir):\n",
    "            if len(files) < 5400:\n",
    "                break;\n",
    "            for i in range(5400):\n",
    "                os.rename(os.path.join(os.path.join(\"./Dataset/valid\",os.path.basename(subsubdir)),files[i]), os.path.join(os.path.join(\"./Dataset/train\",os.path.basename(subsubdir)),files[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationTechnique(Enum):\n",
    "    NoAugmentation = 0\n",
    "    Rotation = 1\n",
    "    Flipping = 2\n",
    "    Contrast = 3\n",
    "    Brightness = 4\n",
    "    RandomErasing = 5\n",
    "\n",
    "class ModelType(Enum):\n",
    "    MobileNet =1\n",
    "    EfficientNet = 2\n",
    "\n",
    "class OptmizerType(Enum):\n",
    "    Adam = 1\n",
    "    Sgd=2\n",
    "\n",
    "class Model:\n",
    "    def fit(self,batch_size,epochs,train_data_generator,valid_data_generator):\n",
    "        pass\n",
    "    def predict(self,test_data_generator):\n",
    "        pass\n",
    "    def __init__(self,optimizer,loss,metrics):\n",
    "        pass\n",
    "\n",
    "# TODO: implement those classes for models\n",
    "def CustomMobileNetModel(Model):\n",
    "    def __init__(self,optimizer,loss,metrics):\n",
    "        # Load MobileNetV3Large without top classification layer\n",
    "        base_model = MobileNetV3Large(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "\n",
    "        # Freeze the base model layers\n",
    "        base_model.trainable = False\n",
    "\n",
    "        # Add additional layers on top of MobileNetV3Large\n",
    "        model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')  # Output layer with size 10 for classification\n",
    "        ])\n",
    "        # Compile the model\n",
    "        model.compile(optimizer, loss, metrics)\n",
    "        self.model=model\n",
    "\n",
    "    def fit(self,batch_size,epochs,train_data_generator,valid_data_generator):\n",
    "        self.model.fit(\n",
    "        train_data_generator,\n",
    "        steps_per_epoch=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_data_generator,\n",
    "        validation_steps=batch_size\n",
    "        )\n",
    "    def predict(self,test_data_generator):\n",
    "        self.model.predict(test_data_generator, steps=len(test_data_generator))\n",
    "\n",
    "def CustomEfficientNetModel(Model):\n",
    "    def __init__(self,optimizer,loss,metrics):\n",
    "        # Load MobileNetV3Large without the top classification layer\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "        \n",
    "        # Freeze the base model layers\n",
    "        base_model.trainable = False\n",
    "        # Add additional layers on top of EfficientNet\n",
    "        model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')  # Output layer with size 10 for classification\n",
    "        ])\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        self.model=model\n",
    "    def fit(self,batch_size,epochs,train_data_generator,valid_data_generator):\n",
    "        self.model.fit(\n",
    "        train_data_generator,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_data_generator,\n",
    "        )\n",
    "    def predict(self,test_data_generator):\n",
    "        predictions = self.model.predict(test_data_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createModel(modelType, optimizer, loss, metrics)->Model:\n",
    "    match modelType:\n",
    "        # TODO: Implement the creation of these models and then return the model\n",
    "        case ModelType.MobileNet:\n",
    "            return CustomMobileNetModel(optimizer,loss,metrics)\n",
    "        case ModelType.EfficientNet:\n",
    "            return NotImplementedError\n",
    "\n",
    "def augumentData(data, technique, seed):\n",
    "    match technique:\n",
    "        case AugmentationTechnique.Rotation:\n",
    "            return ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            )\n",
    "\n",
    "    return data\n",
    "\n",
    "def getAccuracy(y_result, y_test):\n",
    "    correct_amount =0 \n",
    "    for i, result in enumerate(y_result):\n",
    "        if result == y_test[i]:\n",
    "            correct_amount+=1\n",
    "    return correct_amount/len(y_test)\n",
    "\n",
    "def getOptimizer(type, learningRate):\n",
    "    match type:\n",
    "        case OptmizerType.Adam:\n",
    "            return Adam(learning_rate=learningRate)\n",
    "        case OptmizerType.Sgd:\n",
    "            return 'sgd'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays containing different hyper-parameter values\n",
    "\n",
    "TODO: Handle hyperparameters related to regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AugmentationTechnique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m      8\u001b[0m numberOfEpochs \u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# regularization\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# augmentation\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m augmentationTechniques \u001b[38;5;241m=\u001b[39m[\u001b[43mAugmentationTechnique\u001b[49m\u001b[38;5;241m.\u001b[39mNoAugmentation,AugmentationTechnique\u001b[38;5;241m.\u001b[39mRotation,AugmentationTechnique\u001b[38;5;241m.\u001b[39mFlipping,AugmentationTechnique\u001b[38;5;241m.\u001b[39mContrast,AugmentationTechnique\u001b[38;5;241m.\u001b[39mBrightness,AugmentationTechnique\u001b[38;5;241m.\u001b[39mRandomErasing]\n\u001b[0;32m     17\u001b[0m seeds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m123\u001b[39m,\u001b[38;5;241m42\u001b[39m,\u001b[38;5;241m56\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AugmentationTechnique' is not defined"
     ]
    }
   ],
   "source": [
    "train_dir = '../datasets/cinic-10/train'\n",
    "valid_dir = '../datasets/cinic-10/valid'\n",
    "test_dir = '../datasets/cinic-10/test'\n",
    "image_size = (32, 32)\n",
    "# training process\n",
    "batchSizes =[64]\n",
    "learningRates = [0.001]\n",
    "numberOfEpochs =[10]\n",
    "\n",
    "# regularization\n",
    "\n",
    "\n",
    "\n",
    "# augmentation\n",
    "augmentationTechniques =[AugmentationTechnique.NoAugmentation,AugmentationTechnique.Rotation,AugmentationTechnique.Flipping,AugmentationTechnique.Contrast,AugmentationTechnique.Brightness,AugmentationTechnique.RandomErasing]\n",
    "\n",
    "seeds = [123,42,56]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main pipeline loop\n",
    "\n",
    "TODO: repeat the experiments 3 times, different seed each time. I want to first test if it works once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performExperiment(modelType,X,y, X_test, y_test):\n",
    "    results = []\n",
    "    valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    for batchSize in batchSizes:\n",
    "        for learningRate in learningRates:\n",
    "            for epochNumber in numberOfEpochs:\n",
    "                for augmentation in augmentationTechniques:\n",
    "                    train_augmented_data_generator = augumentData(X,augmentation,seeds[0])\n",
    "\n",
    "                    train_generator = train_augmented_data_generator.flow_from_directory(\n",
    "                        train_dir,\n",
    "                        target_size=image_size,\n",
    "                        batch_size=batchSize,\n",
    "                        class_mode='categorical'\n",
    "                    )\n",
    "\n",
    "                    valid_generator = valid_datagen.flow_from_directory(\n",
    "                        valid_dir,\n",
    "                        target_size=image_size,\n",
    "                        batch_size=batchSize,\n",
    "                        class_mode='categorical'\n",
    "                    )\n",
    "\n",
    "                    test_generator = valid_datagen.flow_from_directory(\n",
    "                        test_dir,\n",
    "                        target_size=image_size,\n",
    "                        batch_size=batchSize,\n",
    "                        class_mode='categorical'\n",
    "                    )\n",
    "                    # create the model\n",
    "                    \n",
    "                    model = createModel(modelType,optimizer=getOptimizer(OptmizerType.Adam,0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    # train the model \n",
    "                    model.fit(train_generator, y,batch_size=batchSize,epochs=epochNumber,valid_data_generator=valid_generator)\n",
    "\n",
    "                    # get accuracy\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    accuracy = getAccuracy(y_pred,y_test)\n",
    "\n",
    "                    # append to results\n",
    "                    results.append({'accuracy':accuracy,'augmentation': augmentation,'batchSize':batchSize,'learningRate':learningRate,'numberOfEpochs':numberOfEpochs})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNUSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HyperParameter(Enum):\n",
    "    BatchSize=1\n",
    "    LearningRate =2\n",
    "    NumberOfEpochs =3\n",
    "\n",
    "class HyperParameters:\n",
    "    def __init__(self, batchSizes, learningRates, numberOfEpochs):\n",
    "        self.batchSizes=batchSizes\n",
    "        self.learningRates=learningRates\n",
    "        self.numberOfEpochs=numberOfEpochs\n",
    "        self.currentIndex =0\n",
    "    \n",
    "    def getNextHyperParameter(self):\n",
    "        if self.currentIndex<len(self.batchSizes):\n",
    "            return self.batchSizes[self.currentIndex], HyperParameter.BatchSize\n",
    "        elif self.currentIndex<(len(self.batchSizes+self.learningRates)):\n",
    "            return self.learningRates[self.currentIndex-len(self.batchSizes)], HyperParameter.LearningRate\n",
    "        elif self.currentIndex<(len(self.batchSizes)+len(self.learningRates)+len(self.numberOfEpochs)):\n",
    "            return self.num\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
